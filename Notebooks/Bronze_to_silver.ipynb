{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11f06446-41f7-4f58-b1ff-13d277fae5c0",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-04-05T03:06:45.9641539Z",
       "execution_start_time": "2025-04-05T03:06:45.9082558Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "f2189c81-fd7b-4529-9e18-e07e68abbf5c",
       "queued_time": "2025-04-05T03:06:40.0757932Z",
       "session_id": "77426ae0-30ad-4ce1-aa04-a1a8521a5dda",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 3,
       "statement_ids": [
        3
       ]
      },
      "text/plain": [
       "StatementMeta(, 77426ae0-30ad-4ce1-aa04-a1a8521a5dda, 3, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run file_paths_updt Copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f9b54c-cbaa-4e6f-ab99-8213661f6c01",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-04-05T03:12:50.1355797Z",
       "execution_start_time": "2025-04-05T03:12:49.8448734Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "7674fc87-420e-4032-80e2-e5613a793521",
       "queued_time": "2025-04-05T03:12:49.8436773Z",
       "session_id": "77426ae0-30ad-4ce1-aa04-a1a8521a5dda",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 7,
       "statement_ids": [
        7
       ]
      },
      "text/plain": [
       "StatementMeta(, 77426ae0-30ad-4ce1-aa04-a1a8521a5dda, 7, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run file_paths_updt Copy\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "import sys\n",
    "\n",
    "def brnze_silver():\n",
    "    try:\n",
    "        df_new = spark.read.parquet(Bronze+'//'+'hr_data_bronze.parquet')\n",
    "        filtered = [i for i in df_new.columns if i!='termdate'] \n",
    "        df = df_new.withColumn('hire_date',to_date(col(\"hire_date\"), \"M/d/yyyy\"))\\\n",
    "                   .withColumn('birthdate',to_date(col(\"birthdate\"),\"M/d/yyyy\"))\\\n",
    "                   .withColumn('employee_id',regexp_replace(col('id'),'-',''))\n",
    "        pcs_df = df.dropDuplicates().dropna(subset=filtered)\n",
    "        dfnew = pcs_df.withColumn('emp_id_int',row_number().over(Window.orderBy('employee_id')))\n",
    "        dfnew.write.format(\"delta\").mode('overwrite').save(Silver+'//'+'hr_data_silver')\n",
    "    except:\n",
    "        print(sys.exc_info())\n",
    "\n",
    "brnze_silver()\n",
    "\n",
    "# The brnze_silver() function reads the Parquet file from the Bronze layer, cleans the data by formatting dates, \n",
    "# removing duplicates, handling nulls (except for termdate), and fixing employee IDs. It then adds a unique integer \n",
    "# ID (emp_id_int) to each employee using a row number window function and saves the cleaned data in Delta format to the Silver layer.\n",
    "#  Errors are caught and printed if they occur."
   ]
  }
 ],
 "metadata": {
  "dependencies": {
   "lakehouse": {
    "known_lakehouses": [
     {
      "id": "decf4dae-3d7c-42dc-a870-013b4552bd91"
     }
    ]
   }
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  },
  "synapse_widget": {
   "state": {},
   "version": "0.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
